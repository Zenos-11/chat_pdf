import os
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_community.vectorstores import Chroma
from langchain_core.documents import Document
from openai import OpenAI  # æˆ‘ä»¬ç”¨ OpenAI çš„åº“æ¥è°ƒç”¨ DeepSeekï¼ˆå®ƒä»¬å…¼å®¹ï¼‰

# ================= é…ç½®åŒºåŸŸ =================
# æ›¿æ¢æˆä½ çš„ DeepSeek API Key
DEEP_SEEK_API_KEY = "sk-4d6e671585284c19b12a2fa9eba546b3"
BASE_URL = "https://api.deepseek.com"  # DeepSeek çš„å®˜æ–¹åœ°å€

# ================= 1. å‡†å¤‡å·¥ä½œ (å›¾ä¹¦ç®¡ç†å‘˜) =================
print(">>> 1. [ç®¡ç†å‘˜] æ­£åœ¨åˆå§‹åŒ–æœ¬åœ°å‘é‡æ¨¡å‹...")
embeddings = HuggingFaceEmbeddings(model_name="moka-ai/m3e-base")

# æ¨¡æ‹ŸçŸ¥è¯†åº“æ•°æ® (çœŸå®åœºæ™¯ä¸‹è¿™é‡Œæ˜¯è¯» PDF)
raw_texts = [
    "DeepSeek-V3 æ˜¯ä¸€ä¸ªå¼ºå¤§çš„æ··åˆä¸“å®¶ (MoE) è¯­è¨€æ¨¡å‹ï¼Œæ€»å‚æ•°é‡ä¸º 671Bã€‚",
    "Docker çš„ -p å‚æ•°ç”¨äºç«¯å£æ˜ å°„ï¼Œæ ¼å¼ä¸º å®¿ä¸»æœºç«¯å£:å®¹å™¨ç«¯å£ã€‚",
    "å°æ˜çš„ç§˜å¯†ï¼šä»–è¡¨é¢ä¸Šæ˜¯ç¨‹åºå‘˜ï¼Œå®é™…ä¸Šæ˜¯å›½å®¶ä¸€çº§é¢ç‚¹å¸ˆï¼Œæœ€æ“…é•¿åšæµæ²™åŒ…ã€‚",
]
documents = [Document(page_content=text) for text in raw_texts]

print(">>> 2. [ç®¡ç†å‘˜] æ­£åœ¨å°†æ•°æ®å­˜å…¥å‘é‡åº“...")
# åˆ›å»ºä¸€ä¸ªä¸´æ—¶çš„å†…å­˜æ•°æ®åº“
db = Chroma.from_documents(documents, embeddings)

# ================= 2. ç”¨æˆ·æé—® =================
user_query = "å°æ˜çš„çœŸå®èº«ä»½æ˜¯ä»€ä¹ˆï¼Ÿ"
print(f"\n>>> ç”¨æˆ·æé—®: {user_query}")

# ================= 3. æ£€ç´¢ (æ‰¾æœ€åƒ) =================
print(">>> 3. [ç®¡ç†å‘˜] æ­£åœ¨å»ä¹¦æ¶ä¸Šæ‰¾èµ„æ–™...")
# æ‰¾æœ€ç›¸å…³çš„ 1 æ¡ä¿¡æ¯
results = db.similarity_search(user_query, k=1)
retrieved_text = results[0].page_content

print(f"    -> æ‰¾åˆ°äº†è¿™æ¡èµ„æ–™: ã€Œ{retrieved_text}ã€")
print("    -> (æ­¤æ—¶è¿˜æ²¡æœ‰é€»è¾‘ï¼Œåªæ˜¯æŠŠå­—æ‰¾å‡ºæ¥äº†)")

# ================= 4. ç»„è£… (å…³é”®æ­¥éª¤ï¼) =================
# è¿™å°±æ˜¯ RAG çš„é­”æ³•ï¼šæŠŠâ€œé—®é¢˜â€å’Œâ€œèµ„æ–™â€æ‹¼åœ¨ä¸€èµ·ï¼Œéª— AI è¯´è¿™æ˜¯å®ƒè‡ªå·±çŸ¥é“çš„
prompt = f"""
ä½ æ˜¯ä¸€ä¸ªèªæ˜çš„åŠ©æ‰‹ã€‚è¯·æ ¹æ®ä¸‹é¢çš„ã€å‚è€ƒèµ„æ–™ã€‘å›ç­”ç”¨æˆ·çš„ã€é—®é¢˜ã€‘ã€‚
å¦‚æœä½ åœ¨èµ„æ–™é‡Œæ‰¾ä¸åˆ°ç­”æ¡ˆï¼Œå°±è¯šå®åœ°è¯´ä¸çŸ¥é“ï¼Œä¸è¦çç¼–ã€‚

ã€å‚è€ƒèµ„æ–™ã€‘ï¼š
{retrieved_text}

ã€é—®é¢˜ã€‘ï¼š
{user_query}
"""

print("\n>>> 4. [ç³»ç»Ÿ] æ­£åœ¨æŠŠèµ„æ–™å’Œé—®é¢˜æ‰“åŒ…å‘ç»™ DeepSeek (è€æ•™æˆ)...")

# ================= 5. æ¨ç† (è€æ•™æˆå‘æŒ¥é€»è¾‘) =================
client = OpenAI(api_key=DEEP_SEEK_API_KEY, base_url=BASE_URL)

response = client.chat.completions.create(
    model="deepseek-chat",
    messages=[
        {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªåŸºäºçŸ¥è¯†åº“çš„é—®ç­”åŠ©æ‰‹ã€‚"},
        {"role": "user", "content": prompt},
    ],
    temperature=0.1,  # æ¸©åº¦è®¾ä½ç‚¹ï¼Œè®©å®ƒä¸¥è°¨ä¸€ç‚¹
)

answer = response.choices[0].message.content

print("\n" + "="*30)
print(f"ğŸ¤– DeepSeek çš„å›ç­”:\n{answer}")
print("="*30)